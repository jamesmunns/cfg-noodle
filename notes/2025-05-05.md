# Where am I with the storage work

I've started looking into sequential storage, and familiarizing myself with the API it provides. I've also looked into ekv a bit, to understand how they both work.

One thing I'm struggling with is the transactionality of certain operations, particularly around schema changes, AND how to preserve old versions of a piece of data in the case of a rollback event.

example:

```rust
// sw v1.0
struct ConfigV1 {
    brightness: f32,
    vibration: f32,
}

// sw v1.1
struct ConfigV2 {
    brightness: f32,
    volume: f32, // +added
    vibration: f32,
}
```

## Try to do multi-versioning

How could we attempt to keep old versions of the data around, or multiple versions of the same "key" with different "value" schemas?

### "That's my garbage!"

We could try to use sequential-storage's ability to see "old" versions of k:v pairs as a way to retrieve older versions of data. We could store the schema (or a hash of the schema) in the value, but use the same key for the newer write.

In this case, we'd *hope* that the old version is still visible in `featch_all_items`, and we'd have some way of determining the newest-but-compatible version of the data. This would rely on the fact that old versions of the same key aren't "garbage collected" immediately. However this has the downsides that:

* EVENTUALLY the old record will be GC'd. We would need to overwrite the new version to ensure that the one we want sticks around forever
* We lose any changes that were only made to the new version. The customer has said that they don't want to "roll back" to an old snapshot
* We aren't guaranteed that ANY garbage will live for any deterministic amount of time
* We need to iterate the whole storage FOR EVERY KEY to find the newest garbage
* We need to have some kind of reliable "sequence number" for writes to tell what the "newest garbage" is

Overall, I don't think this approach is viable. It has a lot of downsides, and even despite that is still a requirements mismatch from what the customer wants. For example, if the following sequence of events occurred:

* V1.0 of the software wrote `ConfigV1`, with a "brightness" of `0.5`
* The software was updated to v1.1
* The software writes `ConfigV2`, with a "brightness" of `0.9`
* The software was rolled back to v1.0
* The software queries the config to check the "brightness" field

The customer WANTS to see `0.9`, NOT `0.5`. This means just ignoring the new version of the config is not acceptable.

### "Store multiple versions with different keys"

One thing we could do is have the path + schema combined to really durably store old versions of the same data.

Something like:

* key: `"path/to/config" + hash(schema(ConfigV1))`, value: `serialized(ConfigV1)`
* key: `"path/to/config" + hash(schema(ConfigV2))`, value: `serialized(ConfigV2)`

This would still not match what the customer wants, because they don't necessarily want a "full rollback" of config data. We'd still lose new changes.

Additionally, we'd have to figure out when we could "garbage collect" old versions of the same data, e.g. removing `"path/to/config" + hash(schema(ConfigV1))` at SOME POINT after `"path/to/config" + hash(schema(ConfigV2))` exists.

We'd STILL have to figure out how to be forward compatible, e.g. read `"path/to/config" + hash(schema(ConfigV1))` the first time we boot into SW v1.1.

## Just don't do multi-versioning

One approach to multi-versioning is to not do it at all, and instead just store the latest version, essentially using the default `get` operation of sequential-storage::Map. This requires that in the case of a rollback, we could have a newer version of the schema than we know about, meaning that we need to use a query-like API for grabbing data.

This means that the v1.1 software needs to be able to "query" the data source. When deserializing, it needs to ask for:

* find the "brightness" field, as an `f32`
* find the "vibration" field, as an `f32`

When doing this, it needs to skip the newly added `volume` field.

### Hand rolling this with `postcard` and `postcard-schema`

One way to achieve this is to store everything in a headered form, where every item is an array element. Something like:

```rust
[
    // &str         1 byte tag         encoded form
    ("brightness",  type_tag::<f32>(), [u8]         ),
    ("volume",      type_tag::<f32>(), [u8]         ),
    ("vibration",   type_tag::<f32>(), [u8]         ),
]
```

This achieves atomicity, if the total write fails, we don't care about partial updates. This would make the key value store some moral equivalent of `Key<&str, Records>`.

This would require a custom derive for configuration structures, since we'd need to "seek" data instead of just read it sequentially like postcard does.

We'd also need to define how to handle things like enums work.

We could instead...

### Just use CBOR

The form described above is more or less a re-implementation of what CBOR does. We might just want to use CBOR with the ability to query fields.

`minicbor` is one option, and it has a [derive crate]. It requires annotation of all fields with a numerical index to retain compatibility. There are also some limitations on what you can/can't add, particularly around enums. It does NOT encode the name of fields, and instead uses the mandatory field tags. It does support nullable fields if they are rust `Option`s. I'm unsure if it supports field reordering if the tag numbers are still coherent.

Skipping some fields [requires `alloc`]. It is unclear of "indefinite maps or arrays inside of regular maps or arrays" is something we are likely to run into.

[derive crate]: https://docs.rs/minicbor-derive/0.16.2/minicbor_derive/index.html
[requires `alloc`]: https://docs.rs/minicbor-derive/0.16.2/minicbor_derive/index.html#fn1

Example:

```rust
use minicbor::{Encode, Decode};

#[derive(Encode, Decode)]
struct Point {
    #[n(0)] x: f64,
    #[n(1)] y: f64
}

#[derive(Encode, Decode)]
struct ConvexHull {
    #[n(0)] left: Point,
    #[n(1)] right: Point,
    #[n(2)] points: Vec<Point>,
    #[n(3)] state: Option<State>
}

#[derive(Encode, Decode)]
enum State {
    #[n(0)] Start,
    #[n(1)] Search { #[n(0)] info: u64 }
}
```

I'd need to figure out how to "mesh" `minicbor`'s `Encode` and `Decode` traits with `sequential_storage`'s `Value` trait. This is probably tractable.
