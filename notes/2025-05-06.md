# How to handle the "path"?

Up to now, I've been planning on using a string-like path, emulating filesystem paths for configuration. This would allow people to define a path like:

```rust
const CONFIG_PATH = Path::from_str("mymodule/config");
#[derive(Debug, Decode, Encode)]
struct ConfigV1 {
    #[n(1)]
    brightness: f32,
    #[n(2)]
    volume: f32,
}
// ...
let config: ConfigV1 = flash.load(CONFIG_PATH).await?;
```

This "path" would be used as the Key in the Key:Value store. Configuration paths would be expected to be "globally unique", e.g. within all consumers of the storage service in a single deployed device, all configuration paths would need to be unique.

## What to store

This has one challenge, `sequential_storage::Key` does not allow for borrowed keys, because they may need to be stored in the Cache structure. This leaves us with a couple of potential options to solve this:

### Option A: Use a fixed-size string

We could use something like `heapless::String`, which would have a fixed upper size. This could be some reasonable limit, like 8-32 characters. This would require some additional overhead for the "len" field as well. We could make the len field 1-byte, and use the remaining space to store the key, to avoid additional alignment requirements.

This would introduce a tradeoff - the larger the strings we allow, the larger the Cache will need to be. A quick table of how large the key cache will need to be (not counting any additional overhead, only the key value), as well as the space on disk taken to store keys (not counting any additional encoding overhead):

| ttl entries   | 7 byte keys   | 15 byte keys  | 31 byte keys  |
| :---          | :---          | :---          | :---          |
| 16            | 128B          | 256B          | 512B          |
| 64            | 512B          | 1KiB          | 2KiB          |
| 256           | 2KiB          | 4KiB          | 8KiB          |
| 1024          | 8KiB          | 16KiB         | 32KiB         |

If we assume the average "value" size is 16-64B, and we have a total amount of "value" storage of 4KiB (based on previous estimates), that means we can expect 64-256 entries.

This means we should expect a key cache size of 512B - 2KiB for 7-byte keys, or 2-8KiB for 31 byte keys. We don't NECESSARILY need to have a cache large enough to hold 100% of all keys, but cache misses are relatively expensive wrt seek time. This may not be an issue if most configuration loading is done at boot, and writes are done relatively rarely.

Messing with encoding, we could get an extra 33% if we force 6-bit ascii-only (7/15/31 bytes becomes 9/20/41 chars), and we could get an extra 60% if we force a simple 5-bit encoding with something like `[A-Z0-4/]` (7/15/31 bytes becomes 11/24/49 chars).

The downside with smaller path strings is that they need to be globally unique. If we use a simple convention of "module" and "usage" pairs, it might look something like:

```text
uart                                                - 4 chars
wifi/psk                                            - 8 chars
wifi/ssid                                           - 9 chars
encabulator/grammeter                               - 21 chars
encabulator/bearings/spurving                       - 29 chars
encabulator/reluctance/magneto/calculated           - 41 chars
=======================================================================
|-----|                                             - 7 chars (utf-8)
|-------|                                           - 9 chars (ascii)
|---------|                                         - 11 chars (custom)
|-------------|                                     - 15 chars (utf-8)
|------------------|                                - 20 chars (ascii)
|----------------------|                            - 24 chars (custom)
|-----------------------------|                     - 31 chars (utf-8)
|---------------------------------------|           - 41 chars (ascii)
|----------------------------------------------|    - 49 chars (custom)
```

### Option B: Use a hash

In lieu of storing the entire string, we could instead store a 32-64 bit deterministic hash of the string. We would then use the hash of the path as the primary key.

This has benefits, in that we could use a relatively small key size to represent a wider range of keys, however the downside would be that this introduces us to potential "hash collisions", where two different path strings render to the same hash value.

The chance of a collision can be estimated as the [birthday problem]. Based on our acceptable tolerance for collisions, we can estimate how many keys it would take to reach that threshold:

[birthday problem]: https://en.wikipedia.org/wiki/Birthday_problem

| Chance of collision   | Chance of collision   | 32-bit keys   | 64-bit keys   |
| :---                  | :---                  | :---          | :---          |
| 10<sup>-12</sup>      | "one in a trillion"   | 2.0 entries   | 6.1k entries  |
| 10<sup>-9</sup>       | "one in a billion"    | 2.9 entries   | 190k entries  |
| 10<sup>-6</sup>       | "one in a million"    | 93 entries    | 6.1M entries  |
| 10<sup>-3</sup>       | "one in a thousand"   | 2.9k entries  | 190M entries  |

This is still however "statistical", we COULD see collisions with fewer entries.

As far as space goes, there are great savings with this approach:

| ttl entries   | 32-bit hash   | 64-bit hash   |
| :---          | :--           | :---          |
| 16            | 64B           | 128B          |
| 64            | 256B          | 512B          |
| 256           | 1KiB          | 2KiB          |
| 1024          | 4KiB          | 8KiB          |

Based on our expectation that we will have 64-256 entries total, and setting a "reasonable" collision probability at "one in a million", this means that we likely need to use a 64-bit
hash.

One downside of this approach is that performing a 64-bit hash on a 32-bit device is potentially more expensive than a 32-bit hash would be, or would require mitigation to ensure we don't end up increasing the code size and performance cost of this hashing. This is not prohibitively expensive or complex, but should be considered in the "total cost" of this approach, compared to a more basic string-compare loop. Simple, non-cryptographic hashes, like [fnv1a] are achievable with only 64-bit multiplication and 64-bit addition.

[fnv1a]: https://en.wikipedia.org/wiki/Fowler%E2%80%93Noll%E2%80%93Vo_hash_function

Another mitigation is that it is possible to perform this hashing at compile time in most cases, particularly if paths are used as `const`s. Crates like [`const-fnv1a-hash`] are readily available. It should be possible to do this with code that looks like this:

[`const-fnv1a-hash`]: https://docs.rs/const-fnv1a-hash

```rust
#[derive(Clone, PartialEq, Eq)]
struct PathHash {
    hash: [u8; 8],
}

impl PathHash {
    pub const fn from_str(s: &str) -> Self {
        let buf = s.as_bytes();
        Self::from_slice(buf)
    }

    pub const fn from_slice(buf: &[u8]) -> Self {
        let hash: u64 = const_fnv1a_hash::fnv1a_hash_64(buf, None);
        let hash = hash.to_le_bytes();
        Self { hash }
    }
}

// Performs the hashing of the provided string at compile time, storing the
// 64-bit (8 byte) hash as a constant value
const CONFIG_PATH = PathHash::from_str("mymodule/config");
```

With hashes calculated at compile time, this cost would be largely mitigated, treating hashes as opaque "byte slices".

### Option C: Hybrid/`forth` approach

Another option is to mix the two approaches for the key, storing SOME of the raw key, and a hash, in order to attempt to further avoid collisions.

This could include storing info like:

* 1 byte for "length"
* 3-7 bytes of the path, likely the last bytes, or "last bytes after the last separator"
* 4 byte hash

This would mean something like `encabulator/reluctance/magneto/calculated` would become

```rust
Key {
    len: 41,
    path_frag: "cal",
    hash: 0x1234ABCD,
}
```

With the hope that using "high entropy" information like length and a path fragment would mitigate potential collisions.

It's unclear if this is likely to have better results than just using a good 64-bit hash.

### Option D: Some kind of "globally unique" registry

Another option would be to totally eschew emulating "file system paths" to uniquely identify pieces of configuration data.

We could instead expect users to opt-in to some contextually relevant "global registry" of "kinds of configuration", and assign an explicit numerical identifier, e.g. a 32/64-bit number (maybe subdivided, more on that in a bit).

This might not be a great option for general open source "bazaar" style components with no direct method of coordinating "who gets what number".

Examples of this kind of approach include USB's "VID:PID" scheme, where "vendors" are assigned a 16-bit prefix, and can assign up to 65536 "product" IDs. This is also similar to what PCI's vendor/devices/subsystem/class structure is like. This is also similar to Bluetooth's assigned "characteristic" numbers, and OUI numbers used by MAC addresses of network interfaces.

This would change "technological" solutions to the problem with an "organizational" approach, requiring some central repository or other registry of numeric identifiers.

For example, we could have the "vendor" portion of the identity tied to a company or crate, and allow companies/crates to assign whatever "device" identifier to different configuration fields.

This approach is extremely space efficient, likely solvable in 2-16 bytes, at the cost of "organizational" effort to maintain the list, either publicly or within some set of collaborative vendors/maintainers.

## Challenges

This leaves us with two failure modes we hope to mitigate:

1. "accidental" key collisions
    * for example if two unrelated paths happen to produce a collision of keys
    * particularly in the case of using a hash of the path
    * e.g. `wifi/ssid` and `wifi/psk` happen to render to the same hashed value
2. "direct" key collisions
    * Two different parts of the system use the SAME key for DIFFERENT kinds of data
    * e.g. the "UART" subsystem and the "WIFI" subsystem both try and store their data under the name `config`.

The first problem is discussed pretty actively above. The second challenge is a bit harder to handle.

### Picking unique-enough names

We could potentially implicitly/explicitly prefix the paths with a "crate" or "module" name, however doing this automatically (based on crate metadata, or file metadata) could mean that renaming crates or files could cause a "breaking change" to the path.

e.g. if crate `encabulator` has a file at `encabluator/src/options.rs`, and declares a configuration item named `parameters`, we could automatically prefix this, something like `encabulator/options/parameters`.

If the crate `encabulator` was renamed `retro-encabulator`, this would lead to us "invalidating" all current configuration values stored on end-devices. This might lead to requiring "overridable" names, so backwards compatibility could be maintained. The same challenge exists if we attempt to use file/module path names as a prefix to user-chosen identifiers.

We could also make this explicit, and attempt to enforce this with code review, asking users to provide a "scope name" and "leaf name" when building a path. Something like:

```rust
impl PathHash {
    pub const fn new(group: &str, system: &str, name: &str) -> Self {
        // ...
    }
}

const CONFIG_PATH: PathHash = PathHash::new(
    "encabulator",
    "options",
    "parameters",
);
```

### Why can't this "just work"?

The root issue here is that we use a global-scoped "key" for storing values. Additionally, if the only operations we expose are:

* load/read (by key name)
* store/write (by key name)
* remove (by key name)

we could run into issues where two pieces of code want to use the same "key" name.

This is partially exacerbated by the fact that we WANT the ability to change schemas over time, which also means that "a mismatch in shape of the value data in storage" isn't necessarily a perfect way to detect "direct" key collisions.

### How can we detect this?

Ideally, we'd like to statically detect collisions ("accidental" OR "direct"), at compile time. This is challenging to do when configuration definitions may be spread over multiple crates. I'm not sure at the moment HOW we would do this, we could potentially look into using "linker script trickery" to try and cause link-time errors on conflicts. "Option D" above, using a central registry, would also make this easier/possible to catch.

As the "next best" option, we'd like to detect this at runtime at an early boot stage. This could be possible using something like the `linkme` crate, and attempting to detect collisions at boot time, meaning we are more likely to catch this in early testing, rather than "in the field". This could increase overhead and boot time.

As the "least okay" option, we'd like to catch this at runtime, e.g. if we attempt to store "wifi configuration" data to a key that already holds "uart configuration" data. This could be possible at store time, by checking for existing keys, and seeing if the current value can be decoded using the same type we want to write. This still would be relatively "late" in the development process, and would require extensive integration/system testing to ensure we caught it before making it "in the field".

Finally, the last option is "we don't catch this", meaning that the "wifi configuration" just overwrites the "uart configuration". This would cause issues when later attempting to load uart configuration. The failure modes here might be that the two configurations will "fight", constantly overwriting each other back to factory defaults.

For all solutions in this category, we must also consider changes *over time*, e.g. even if there is no collision within the current firmware version, did a PREVIOUS version of the firmware have a key that now collides with our current set of keys?
